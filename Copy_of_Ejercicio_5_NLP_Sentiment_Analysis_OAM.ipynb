{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "colab": {
      "name": "Copy of Ejercicio 5 - NLP - Sentiment Analysis",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brroavendano/test-churn/blob/main/Copy_of_Ejercicio_5_NLP_Sentiment_Analysis_OAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFF63rsMfbI"
      },
      "source": [
        "# Ejercicio 5 - Análisis de sentimientos en texto no-estructurado (NLP)\n",
        "\n",
        "La idea es realizar un simple análisis de sentimiento desde comentarios en medios sociales, por medio de un modelo de clasificación supervisada, que entrega dos posibles valores desde el texto: es un comentario POSITIVO o es NEGATIVO. En este caso no se consideran los neutros. Si algún comentario podría ser definido como neutro por un humano, para este ejemplo fue asociado a positivo o negativo.\n",
        "\n",
        "## Contexto: Análisis de Texto de Comentarios en Medios Sociales de diversos países (Chile, Arg, otros)\n",
        "\n",
        "Este conjunto de datos generado en 2016 por R:Solver y compartido parcialmente para este tipo de ejercicios, consiste en dos columnas: el texto del comentario, y una clasificación dentro de dos alternativas, positivo o negativo.\n",
        "\n",
        "El gran objetivo final a resolver con este ejemplo, es lograr predecir el sentimiento, descrito en la variable de clasificación. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Instrucciones Generales\n",
        "\n",
        "Todos los alumnos, ya sea en grupo, o individualmente (si no tienen compañeros) deben contestar las preguntas que se indicarán, en un email que se deberá enviar al terminar el ejercicio, **incluyendo, en cada respuesta, un pantallazo del resultado y un comentario intepretativo de esos resultados**.\n",
        "\n",
        "El formato del contenido del email es el siguiente, considerando que se pide contestar todo dentro del cuerpo del email o en un PDF adjunto como alternativa (No enviar PPT, ni Word, ni tampoco vínculos):\n",
        "\n",
        "To: rsandova@ing.puc.cl\n",
        "\n",
        "Subject: Machine Learning - Ejercicio Sentiment Analysis aaaammdd\n",
        "\n",
        "Integrantes: Apellido Nombre, Apellido Nombre,   (en orden alfabético)\n",
        "\n",
        "Pregunta 1\n",
        "\n",
        "(Tabla con resultados de probar las técnicas de normalización)\n",
        "\n",
        "Conclusión: la más influyente en el resultado es ....\n",
        "\n",
        "Pregunta 2.1\n",
        "\n",
        "Para mejorar los resultados se aplicó ...\n",
        "\n",
        "Pregunta 2.2\n",
        "(Tabla con resultados de probar diferentes combinaciones)\n",
        "\n",
        "La mejor proporción entrenamiento/validación es de ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsvny1wYwsT"
      },
      "source": [
        "## Actividad Preparatoria: Instalar librerías de modelos de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8D6ajXY2T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205ef4fd-df27-44f8-9c5f-8c2e455cbaea"
      },
      "source": [
        "install.packages('e1071')\n",
        "install.packages('caret')\n",
        "install.packages('caTools')\n",
        "install.packages('tm')\n",
        "install.packages('SnowballC')\n",
        "install.packages('nnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘proxy’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘listenv’, ‘parallelly’, ‘future’, ‘globals’, ‘future.apply’, ‘progressr’, ‘numDeriv’, ‘SQUAREM’, ‘lava’, ‘prodlim’, ‘iterators’, ‘gower’, ‘ipred’, ‘timeDate’, ‘foreach’, ‘plyr’, ‘ModelMetrics’, ‘reshape2’, ‘recipes’, ‘pROC’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘bitops’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘NLP’, ‘slam’, ‘BH’\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q3bYb0RM5bx"
      },
      "source": [
        "## Actividad Preparatoria: Carga de los datos\n",
        "\n",
        "La siguiente celda de código carga los datos desde la URL de origen y luego muestra un encabezado con las primeras filas del dataset, para demostrar la diposición y ejemplos de los datos. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIIKPnj-IRE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "ddb52b92-ffdb-4de2-8943-ff7003ae7bee"
      },
      "source": [
        "# Se declara la URL de dónde obtener los datos\n",
        "theUrlMain <- \"http://RAlize.RSolver.com/RAlize/data/small_sample2019clean.csv\"\n",
        "\n",
        "# Se declaran los nombres de las columnas\n",
        "columnas <- c(\"texto\",\"sentimiento\")\n",
        "\n",
        "# Se cargan datos principales a una estructura (commentsdataset), asignando nombres de atributos a las columnas\n",
        "commentsdataset <- read.csv(file = theUrlMain, header = FALSE, sep = \";\", col.names=columnas, skipNul = TRUE)\n",
        "\n",
        "dim(commentsdataset)\n",
        "head(commentsdataset, 10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4570    2"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 4570\n\\item 2\n\\end{enumerate*}\n",
            "text/markdown": "1. 4570\n2. 2\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4570</li><li>2</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   texto                                                                                                                                     \n",
              "1  David Foronda (Podemos): A favor de regular los transgénicos hay que tener en cuenta la soberanía alimentar.                              \n",
              "2  21% la aprueba 73% la rechaza. Así como va Michelle Bachelet desaparecerá de las encuestas ya no la apoyan ni sus votante                 \n",
              "3  #CUIDATUDINEROMV #LANUEVAMAYORÍA O #LAVIEJAPILLERÍA #AFP #INJUSTAS EDUARDO #FREI RICARDO #LAGOS Y MICHELLE #BACHELET                      \n",
              "4  Ricardo Lagos el mismo que utilizó la LEY ANTITERRORISTA DE PINOCHET para reprimir aplaude a Almagro #NuevaMayoria                        \n",
              "5  @estadonacional INSULZA mi candidato presidencial desde gobierno de otro iluminado Ricardo Lagos. CAPACIDAD INTELIGENCIA PERSONALIDAD.    \n",
              "6  Venezuela contra los transgénicos: Ley de Semillas recibe respaldo de 28 países                                                           \n",
              "7  Como será recordada Michelle Bachelet Aumento del desempleo bajo en economía nula inversión y su nuera Natalia Compagnon. Flor de recuerdo\n",
              "8  #Longueira habrá pensado que por haber salvado el gobierno corrupto de Ricardo Lagos sería perdonado.                                     \n",
              "9  @GobiernodeChile @navarrocl y los transgenicos vendrán etiquetados los pollos las hormonas que les introducen ?                           \n",
              "10 109 nobeles acusan a Greenpeace de crimen contra la humanidad por los transgénicos: Los laureados arremeten.                              \n",
              "   sentimiento\n",
              "1  -1         \n",
              "2  -1         \n",
              "3  -1         \n",
              "4  -1         \n",
              "5   1         \n",
              "6   1         \n",
              "7  -1         \n",
              "8  -1         \n",
              "9  -1         \n",
              "10  1         "
            ],
            "text/latex": "A data.frame: 10 × 2\n\\begin{tabular}{r|ll}\n  & texto & sentimiento\\\\\n  & <chr> & <int>\\\\\n\\hline\n\t1 & David Foronda (Podemos): A favor de regular los transgénicos hay que tener en cuenta la soberanía alimentar.                               & -1\\\\\n\t2 & 21\\% la aprueba 73\\% la rechaza. Así como va Michelle Bachelet desaparecerá de las encuestas ya no la apoyan ni sus votante                  & -1\\\\\n\t3 & \\#CUIDATUDINEROMV \\#LANUEVAMAYORÍA O \\#LAVIEJAPILLERÍA \\#AFP \\#INJUSTAS EDUARDO \\#FREI RICARDO \\#LAGOS Y MICHELLE \\#BACHELET                       & -1\\\\\n\t4 & Ricardo Lagos el mismo que utilizó la LEY ANTITERRORISTA DE PINOCHET para reprimir aplaude a Almagro \\#NuevaMayoria                         & -1\\\\\n\t5 & @estadonacional INSULZA mi candidato presidencial desde gobierno de otro iluminado Ricardo Lagos. CAPACIDAD INTELIGENCIA PERSONALIDAD.     &  1\\\\\n\t6 & Venezuela contra los transgénicos: Ley de Semillas recibe respaldo de 28 países                                                            &  1\\\\\n\t7 & Como será recordada Michelle Bachelet Aumento del desempleo bajo en economía nula inversión y su nuera Natalia Compagnon. Flor de recuerdo & -1\\\\\n\t8 & \\#Longueira habrá pensado que por haber salvado el gobierno corrupto de Ricardo Lagos sería perdonado.                                      & -1\\\\\n\t9 & @GobiernodeChile @navarrocl y los transgenicos vendrán etiquetados los pollos las hormonas que les introducen ?                            & -1\\\\\n\t10 & 109 nobeles acusan a Greenpeace de crimen contra la humanidad por los transgénicos: Los laureados arremeten.                               &  1\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 10 × 2\n\n| <!--/--> | texto &lt;chr&gt; | sentimiento &lt;int&gt; |\n|---|---|---|\n| 1 | David Foronda (Podemos): A favor de regular los transgénicos hay que tener en cuenta la soberanía alimentar.                               | -1 |\n| 2 | 21% la aprueba 73% la rechaza. Así como va Michelle Bachelet desaparecerá de las encuestas ya no la apoyan ni sus votante                  | -1 |\n| 3 | #CUIDATUDINEROMV #LANUEVAMAYORÍA O #LAVIEJAPILLERÍA #AFP #INJUSTAS EDUARDO #FREI RICARDO #LAGOS Y MICHELLE #BACHELET                       | -1 |\n| 4 | Ricardo Lagos el mismo que utilizó la LEY ANTITERRORISTA DE PINOCHET para reprimir aplaude a Almagro #NuevaMayoria                         | -1 |\n| 5 | @estadonacional INSULZA mi candidato presidencial desde gobierno de otro iluminado Ricardo Lagos. CAPACIDAD INTELIGENCIA PERSONALIDAD.     |  1 |\n| 6 | Venezuela contra los transgénicos: Ley de Semillas recibe respaldo de 28 países                                                            |  1 |\n| 7 | Como será recordada Michelle Bachelet Aumento del desempleo bajo en economía nula inversión y su nuera Natalia Compagnon. Flor de recuerdo | -1 |\n| 8 | #Longueira habrá pensado que por haber salvado el gobierno corrupto de Ricardo Lagos sería perdonado.                                      | -1 |\n| 9 | @GobiernodeChile @navarrocl y los transgenicos vendrán etiquetados los pollos las hormonas que les introducen ?                            | -1 |\n| 10 | 109 nobeles acusan a Greenpeace de crimen contra la humanidad por los transgénicos: Los laureados arremeten.                               |  1 |\n\n",
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 10 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>texto</th><th scope=col>sentimiento</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>David Foronda (Podemos): A favor de regular los transgénicos hay que tener en cuenta la soberanía alimentar.                              </td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>21% la aprueba 73% la rechaza. Así como va Michelle Bachelet desaparecerá de las encuestas ya no la apoyan ni sus votante                 </td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>#CUIDATUDINEROMV #LANUEVAMAYORÍA O #LAVIEJAPILLERÍA #AFP #INJUSTAS EDUARDO #FREI RICARDO #LAGOS Y MICHELLE #BACHELET                      </td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>Ricardo Lagos el mismo que utilizó la LEY ANTITERRORISTA DE PINOCHET para reprimir aplaude a Almagro #NuevaMayoria                        </td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>@estadonacional INSULZA mi candidato presidencial desde gobierno de otro iluminado Ricardo Lagos. CAPACIDAD INTELIGENCIA PERSONALIDAD.    </td><td> 1</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>Venezuela contra los transgénicos: Ley de Semillas recibe respaldo de 28 países                                                           </td><td> 1</td></tr>\n",
              "\t<tr><th scope=row>7</th><td>Como será recordada Michelle Bachelet Aumento del desempleo bajo en economía nula inversión y su nuera Natalia Compagnon. Flor de recuerdo</td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>#Longueira habrá pensado que por haber salvado el gobierno corrupto de Ricardo Lagos sería perdonado.                                     </td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>9</th><td>@GobiernodeChile @navarrocl y los transgenicos vendrán etiquetados los pollos las hormonas que les introducen ?                           </td><td>-1</td></tr>\n",
              "\t<tr><th scope=row>10</th><td>109 nobeles acusan a Greenpeace de crimen contra la humanidad por los transgénicos: Los laureados arremeten.                              </td><td> 1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGOO7LFAPDL5"
      },
      "source": [
        "## Ejercicio 1: Entender el efecto de cada técnica de normalización de texto\n",
        "\n",
        "Las técnicas de procesamiento de texto, cuando tienen que realizar \"intrepretaciones\" del texto leído, deben buscar la simplificación del texto para poder trabajar sobre un universo de texto más simple y normalizado. Esto puede considerar evitar la diferencia de mayúscula/minúsculas, eliminar tildes, evitar palabras comunes, usar la raíz de múltiples términos, entre otros.\n",
        "\n",
        "A continuación se aplican algunas de estas diferentes técnicas, mostrando el efecto.\n",
        "\n",
        "**Pregunta 1 (2,5 puntos)**: ¿cuál de todas estas técnicas es la que logra el mayor efecto positivo en los modelos de análisis de sentimiento de la siguiente sección?\n",
        "\n",
        "Se les pide eliminar (comentar la línea de código respectivo) cada instrucción de normalización y comparar cómo afecta en el accuracy de los modelos más abajo, finalmente determinando cuál es la que tiene mayor efecto. Aquella con más efecto es la que provoca que - al ser eliminada - el accuracy de los modelos implementados más adelante baje más. Se recomienda incluir una tabla de ejecuciones comparadas, que sustente la respuesta.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-RkhmupJGPI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "8f12ca21-9eaf-40a4-bc90-c34c552b8afa"
      },
      "source": [
        "library(tm)\n",
        "library(SnowballC)\n",
        "\n",
        "# Construye el Corpus: el universo de texto que se usará para entrenar los modelos.\n",
        "corpus.original <- Corpus(VectorSource(commentsdataset$texto))\n",
        "\n",
        "# Se selecciona y muestra (sin normalizar) un ejemplo aleatorio dentro del corpus\n",
        "random_index <- floor(runif(1, min=0, max=length(corpus.original)))\n",
        "content(corpus.original[[random_index]])\n",
        "\n",
        "################################\n",
        "# NORMALIZACIÓN DEL TEXTO\n",
        "# EJERCICIO: probar eliminando (comentando) una por una estas acciones\n",
        "# para ver cuál tiene mayor efecto en la calidad del modelo de análisis\n",
        "################################\n",
        "corpus <- corpus.original # Se saca una copia ('corpus') de trabajo\n",
        "\n",
        "# Se pasan todas las palabras a minúsculas\n",
        " corpus <- tm_map(corpus, tolower)\n",
        "# Se eliminan todos los signos de puntuación\n",
        " corpus <- tm_map(corpus, removePunctuation)\n",
        "# Se eliminan las stop words (palabras comunes, irrelevantes)\n",
        " corpus <- tm_map(corpus, removeWords, c(stopwords(\"spanish\")))\n",
        "# Se lleva cada palabra a su raíz (stemming)\n",
        " corpus <- tm_map(corpus, stemDocument)\n",
        "\n",
        "# Se muestra el mismo ejemplo aleatorio, pero en texto normalizado\n",
        "content(corpus[[random_index]])\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"Osvaldo Andrade dice que NO ESTUVO en votación en sala en ley que benefició pensión d su esposa Myriam Olate.FALSO\""
            ],
            "text/latex": "'Osvaldo Andrade dice que NO ESTUVO en votación en sala en ley que benefició pensión d su esposa Myriam Olate.FALSO'",
            "text/markdown": "'Osvaldo Andrade dice que NO ESTUVO en votación en sala en ley que benefició pensión d su esposa Myriam Olate.FALSO'",
            "text/html": [
              "'Osvaldo Andrade dice que NO ESTUVO en votación en sala en ley que benefició pensión d su esposa Myriam Olate.FALSO'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in tm_map.SimpleCorpus(corpus, tolower):\n",
            "“transformation drops documents”\n",
            "Warning message in tm_map.SimpleCorpus(corpus, removePunctuation):\n",
            "“transformation drops documents”\n",
            "Warning message in tm_map.SimpleCorpus(corpus, removeWords, c(stopwords(\"spanish\"))):\n",
            "“transformation drops documents”\n",
            "Warning message in tm_map.SimpleCorpus(corpus, stemDocument):\n",
            "“transformation drops documents”\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"osvaldo andrad dice votación sala ley benefició pensión d esposa myriam olatefalso\""
            ],
            "text/latex": "'osvaldo andrad dice votación sala ley benefició pensión d esposa myriam olatefalso'",
            "text/markdown": "'osvaldo andrad dice votación sala ley benefició pensión d esposa myriam olatefalso'",
            "text/html": [
              "'osvaldo andrad dice votación sala ley benefició pensión d esposa myriam olatefalso'"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m6AjrGNtf3x"
      },
      "source": [
        "## Actividad Complementaria: Construcción de un Vocabulario\n",
        "\n",
        "Los clasificadores reciben un X de entrada de una dimensión fija. Por lo tanto los X de este ejemplo de análisis de texto, comentarios de cantidad variable de palabras, no se pueden usar tal cual.\n",
        "\n",
        "Entonces, la siguiente porción de código transforma los comentarios de texto variable en un vector de ocurrencia de palabras desde un vocabulario, el cual se construye referenciando todas las palabras distintas (ya normalizadas) del Corpus. Esto se traduce en que un comentario que tiene la expresión \".. resultados excelentes ... \", tendría una intersección con el comentario \"... excelente como resultó ...\" y por ello podrían ser interpretadas en forma equivalente. \n",
        "\n",
        "Pero el desafío de esta vectorización en base a un vocabulario es la cantidad de dimensiones. Un vocabulario perfectamente puede tener varios miles de palabras diferentes, entonces la dimensión del vector X es de esos varios miles. Por ello, a continuación se busca reducir la dimensionalidad del problema (el tamaño del vocabulario) al reconocer cuáles son los términos más relevantes. Esto se hace con removeSparseTerm y un umbral alto (0.995 reduce la gran cantidad de términos que aparecen en menos de un 99.5% del texto). Mientras mayor es el número, mayor cantidad de términos ocasionales o esporádicos se eliminan. En otras palabras, mientras mayor es el número, mayor es la exigencia para un término de ser considerado valioso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3uvXCD-MdZr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e175897a-a045-45a7-d411-badee6f700d8"
      },
      "source": [
        "#######################################################\n",
        "# Indexación de términos: creación de un Vocabulario\n",
        "#######################################################\n",
        "\n",
        "# Primero una matriz de ocurrencia de términos o palabras (DTM: Document-term matrix).\n",
        "# Las filas son los comentarios y las columnas son las palabras diferentes encontradas.\n",
        "termMatrix <- DocumentTermMatrix(corpus)\n",
        "dim(termMatrix)\n",
        "\n",
        "# Entonces, se eliminan las palabras menos relevantes (sparse terms: términos escasos)\n",
        "# lo que resulta en una reducción dimensional (potencialmente grande)\n",
        "termMatrixLight <- removeSparseTerms(termMatrix, 0.995)\n",
        "dim(termMatrixLight)  # Se puede ver que se reduce significativamente la cantidad de columnas (palabras)\n",
        "\n",
        "# Re-formatea como un DataFrame\n",
        "termMatrixDataframe <- as.data.frame(as.matrix(termMatrixLight))\n",
        "\n",
        "# Se construye el dataset para entrenamiento, agregando la columna del Sentimiento\n",
        "corpus.procesado <- cbind(commentsdataset, as.matrix(termMatrixLight))\n",
        "corpus.procesado$sentimiento <- as.factor(commentsdataset$sentimiento)\n",
        "corpus.procesado$texto <- NULL\n",
        "\n",
        "# Se muestra el vocabulario y su tamaño\n",
        "dim(corpus.procesado)\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4570 9289"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 4570\n\\item 9289\n\\end{enumerate*}\n",
            "text/markdown": "1. 4570\n2. 9289\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4570</li><li>9289</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4570  372"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 4570\n\\item 372\n\\end{enumerate*}\n",
            "text/markdown": "1. 4570\n2. 372\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4570</li><li>372</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4570  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 4570\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 4570\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4570</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gze81qto-1oX"
      },
      "source": [
        "## Ejercicio 2: Ejecución modelos de predicción según conjuntos de entrenamiento y validación\n",
        "\n",
        "En este caso, el dataset de ejemplos etiquetados se divide en dos (Hold-out) para entrenar y validar con conjuntos disjuntos.\n",
        "\n",
        "**Preguntas**\n",
        "\n",
        "2.1.   (3 puntos) ¿Qué técnica adicional de mejora del dataset de entrenamiento puede lograr mejores resultados?\n",
        "\n",
        "2.2.   (0,5 puntos) ¿Cuál proporción entre entrenamiento y validación logra los mejores resultados de Accuracy, Sensitivity, Specificity?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1j2-rNWMcnt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "cc327f51-97cf-465a-ce1f-9cc1fec24cb7"
      },
      "source": [
        "library(caTools)\n",
        "\n",
        "set.seed(12345)\n",
        "\n",
        "# Incluir aquí las líneas que mejoran el conjunto de entrenamiento y evaluación \n",
        "# Esto podría considerar reemplazar las líneas que vienen abajo, que arman estos dos conjuntos en forma simple\n",
        "clean.data.positivo <- corpus.procesado[corpus.procesado$sentimiento == 1,]\n",
        "clean.data.negativo <- corpus.procesado[corpus.procesado$sentimiento == -1,] \n",
        "balance_ratio <- 1.0\n",
        "clean.subdata.positivo <- clean.data.positivo\n",
        "clean.subdata.negativo <- clean.data.negativo[sample(nrow(clean.data.negativo), balance_ratio*dim(clean.data.positivo)[1]), ]\n",
        "\n",
        "# Por ej, se indican estas dos líneas que recolectan los ejemplos de clase positiva y negativa.\n",
        "# Al ver su dimensión, se puede apreciar si están o no balanceados\n",
        "#clean.data.negativo <- corpus.procesado[corpus.procesado$sentimiento == -1,]  \n",
        "#clean.data.positivo <- corpus.procesado[corpus.procesado$sentimiento == 1,]\n",
        "dim(clean.data.negativo)\n",
        "dim(clean.data.positivo)\n",
        "dim(clean.subdata.negativo)\n",
        "dim(clean.subdata.positivo)\n",
        "\n",
        "clean.subdata <- rbind(clean.subdata.positivo, clean.subdata.negativo)\n",
        "\n",
        "corpus.procesado.working <- clean.subdata\n",
        "\n",
        "dim(corpus.procesado.working)\n",
        "\n",
        "ratio <- sample(nrow(corpus.procesado.working),nrow(corpus.procesado.working)*0.90)\n",
        "training.set = corpus.procesado.working[ratio,]\n",
        "testing.set  = corpus.procesado.working[-ratio,]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "# Versión simple para crear conjuntos de entrenamiento y de test\n",
        "# ratio <- sample(nrow(corpus.procesado),nrow(corpus.procesado)*0.80)\n",
        "# training.set = corpus.procesado[ratio,]\n",
        "# testing.set  = corpus.procesado[-ratio,]\n",
        "\n",
        " dim(training.set)\n",
        " dim(testing.set)\n",
        "\n",
        "# head(testing.set, 20)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 3401  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 3401\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 3401\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>3401</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 1169  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 1169\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 1169\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1169</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 1169  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 1169\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 1169\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1169</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 1169  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 1169\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 1169\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>1169</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 2338  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 2338\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 2338\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>2338</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 2104  373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 2104\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 2104\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>2104</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 234 373"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 234\n\\item 373\n\\end{enumerate*}\n",
            "text/markdown": "1. 234\n2. 373\n\n\n",
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>234</li><li>373</li></ol>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82LcskQOnNmH"
      },
      "source": [
        "## Implementación de modelos de clasificación de referencia\n",
        "\n",
        "Habiendo definido y establecido los conjuntos de entrenamiento y de test, a continuación se ejecutan unos pocos modelos de clasificación: Decision Tree, Naive Bayes y más abajo y en una sección separada se encuentra una Red Neuronal (NNET). Cada uno obtiene su resultado, mostrando sus indicadores de desempeño.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOpqb-QInkff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "outputId": "0de718b9-c9ec-4c78-cedb-42c48ff5031a"
      },
      "source": [
        "library(e1071) \n",
        "library(rpart)\n",
        "library(caret)\n",
        "\n",
        "# Decision Tree\n",
        "tree.model <- rpart(sentimiento ~ ., data=training.set, method=\"class\", minbucket=10)\n",
        "tree.predict <- predict(tree.model, testing.set, type = \"class\")\n",
        "print(\"Resultados Árbol de Decisión\")\n",
        "confusionMatrix(tree.predict, as.factor(testing.set$sentimiento)) \n",
        "\n",
        "# Naive Bayes\n",
        "NB_model <- naiveBayes(sentimiento ~ ., data=training.set)\n",
        "NB_predict <- predict(NB_model, testing.set)\n",
        "print(\"Resultados Naive Bayes\")\n",
        "confusionMatrix(NB_predict, as.factor(testing.set$sentimiento)) "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Resultados Árbol de Decisión\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "          Reference\n",
              "Prediction  -1   1\n",
              "        -1 110 108\n",
              "        1    2  14\n",
              "                                          \n",
              "               Accuracy : 0.5299          \n",
              "                 95% CI : (0.4638, 0.5953)\n",
              "    No Information Rate : 0.5214          \n",
              "    P-Value [Acc > NIR] : 0.4226          \n",
              "                                          \n",
              "                  Kappa : 0.0933          \n",
              "                                          \n",
              " Mcnemar's Test P-Value : <2e-16          \n",
              "                                          \n",
              "            Sensitivity : 0.9821          \n",
              "            Specificity : 0.1148          \n",
              "         Pos Pred Value : 0.5046          \n",
              "         Neg Pred Value : 0.8750          \n",
              "             Prevalence : 0.4786          \n",
              "         Detection Rate : 0.4701          \n",
              "   Detection Prevalence : 0.9316          \n",
              "      Balanced Accuracy : 0.5484          \n",
              "                                          \n",
              "       'Positive' Class : -1              \n",
              "                                          "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Resultados Naive Bayes\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "          Reference\n",
              "Prediction  -1   1\n",
              "        -1  48  21\n",
              "        1   64 101\n",
              "                                          \n",
              "               Accuracy : 0.6368          \n",
              "                 95% CI : (0.5716, 0.6984)\n",
              "    No Information Rate : 0.5214          \n",
              "    P-Value [Acc > NIR] : 0.0002393       \n",
              "                                          \n",
              "                  Kappa : 0.2605          \n",
              "                                          \n",
              " Mcnemar's Test P-Value : 5.225e-06       \n",
              "                                          \n",
              "            Sensitivity : 0.4286          \n",
              "            Specificity : 0.8279          \n",
              "         Pos Pred Value : 0.6957          \n",
              "         Neg Pred Value : 0.6121          \n",
              "             Prevalence : 0.4786          \n",
              "         Detection Rate : 0.2051          \n",
              "   Detection Prevalence : 0.2949          \n",
              "      Balanced Accuracy : 0.6282          \n",
              "                                          \n",
              "       'Positive' Class : -1              \n",
              "                                          "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVsGNIiwceZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "1017be8b-4b80-408c-f95b-902d25087620"
      },
      "source": [
        "library(nnet) \n",
        "\n",
        "# Red Neuronal\n",
        "NN_model <- nnet(as.factor(sentimiento) ~ ., data=training.set, size=20, maxit=120, MaxNWts=20000)\n",
        "NN_predict <- predict(NN_model, testing.set, type=\"class\")\n",
        "\n",
        "# A continuación se muestra el resultado de evaluación \n",
        "confTable <- table(NN_predict, testing.set$sentimiento)\n",
        "confTable\n",
        "\n",
        "accuracy <- (confTable[1,1] + confTable[2,2]) / dim(testing.set)[1]\n",
        "print('Accuracy')\n",
        "accuracy\n",
        "\n",
        "sensitivity <- confTable[1,1] / (confTable[1,1] + confTable[1,2])\n",
        "print('Sensitiviy')\n",
        "sensitivity\n",
        "\n",
        "specificity <- confTable[2,2] / (confTable[2,1] + confTable[2,2])\n",
        "print('Specificity')\n",
        "specificity"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# weights:  7481\n",
            "initial  value 1563.317966 \n",
            "iter  10 value 958.234080\n",
            "iter  20 value 547.943372\n",
            "iter  30 value 387.670744\n",
            "iter  40 value 358.611348\n",
            "iter  50 value 352.380151\n",
            "iter  60 value 350.187120\n",
            "iter  70 value 349.486915\n",
            "iter  80 value 349.240788\n",
            "iter  90 value 349.143990\n",
            "iter 100 value 349.104733\n",
            "iter 110 value 349.089217\n",
            "iter 120 value 349.077974\n",
            "final  value 349.077974 \n",
            "stopped after 120 iterations\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          \n",
              "NN_predict -1  1\n",
              "        -1 75 30\n",
              "        1  37 92"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Accuracy\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.7136752"
            ],
            "text/latex": "0.713675213675214",
            "text/markdown": "0.713675213675214",
            "text/html": [
              "0.713675213675214"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Sensitiviy\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.7142857"
            ],
            "text/latex": "0.714285714285714",
            "text/markdown": "0.714285714285714",
            "text/html": [
              "0.714285714285714"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Specificity\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.7131783"
            ],
            "text/latex": "0.713178294573643",
            "text/markdown": "0.713178294573643",
            "text/html": [
              "0.713178294573643"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}